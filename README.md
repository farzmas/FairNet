# Fairness-Aware-Algorithms-for-Network-Analysis 

This repository provides a reference implementations for the Fairness-Aware-Algorithms-for-Network-Analysis(FAI) project which is jointly funded by the National Science Foundation and Amazon under the Fairness in AI program. [**More Information**](http://cse.msu.edu/~ptan/project/fairness/)

## Project Highlight:

* [Fairness-Aware Network Link Prediction](https://github.com/farzmas/FLIP)[1]: Examines the filter bubble problem from the perspective of algorithm fairness ny introducing (1) a dyadic-level fairness criterion based on network modularity measure and (2) a novel framework that combines adversarial network representation learning with supervised link prediction to alleviate the filter bubble problem.
* [Fairness Perception](https://github.com/farzmas/Fairness-Aware-Algorithms-for-Network-Analysis/tree/main/Fairness%20Perception)[2]: Investigates the issue of algorithmic fairness from a network-centric perspective by introducing a notion of fairness perception.


## Project Overview:

As society becomes increasingly reliant on artificial intelligence (AI) technology, there have been growing concerns whether the decisions generated by the AI systems may lead to discriminatory actions against certain protected groups in the population. These concerns have brought increasing scrutiny into the issue of fairness in AI systems and their underlying machine learning algorithms. To overcome this challenge, the overarching goal of this project is to develop fairness-aware algorithms that can maintain the high utility of decisions generated by the AI systems without discriminating against particular subgroups of the population. Specifically, this research will address fundamental issues of fairness in algorithms that utilize network data in their decision making. Successful completion of this project will not only produce novel algorithms for researchers, but also tools that can help practitioners assess the level of inequality present in social networking platforms. The undergraduate and graduate students who participate in the project will be trained to conduct cutting edge research in AI and network science. The investigators will also seek collaborative partnership with research scientists from the industry to apply the developed methods in order to expand their social impact beyond the academic community.

This research fills a major gap in current research on fairness in AI, which has primarily focused on independent and identically distributed (i.i.d.) data. There are still questions remain whether the existing methods are effective when applied to network data. In particular, the link structure of the network often contains information about the protected attributes (e.g., gender, race, or sexual orientation), and thus, must be taken into consideration in the design of fairness-aware machine learning algorithms. To address this issue, the objectives of this project are two-fold: (1) To develop metrics for assessing fairness in network learning algorithms and (2) To design, implement, and evaluate network learning algorithms that consider the tradeoff between fairness and utility of the models for various network analysis tasks and applications (including community detection and link prediction). The innovative methods developed in this project will be a step forward towards bridging the gap between current understanding of fairness in i.i.d. data and its application to network analysis.

## Publications:

1. Farzan Masrour, Tyler Wilson, Heng Yan, Pang-Ning Tan, Abdol-Hossein Esfahanian. Bursting the Filter Bubble: Fairness-Aware Network Link Prediction. In Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI-2020), New York, NY (2020). 

2. Farzan Masrour, Pang-Ning Tan, and Abdol-Hossein Esfahanian. Fairness Perception from a Network-Centric Perspective. To appear in Proceedings of the 20th IEEE International Conference on Data Mining, Sorrento, Italy (2020).


